apiVersion: batch/v1
kind: Job
metadata:
  name: datafabric-job
  namespace: {{ .Values.cpd_namespace }}
spec:
  template:
    metadata:
      name: df-setup-pod
    spec:
      restartPolicy: Never
      serviceAccountName: data-fabric-sa
      volumes:
        - name: df-scripts
          configMap:
            name: datafabric-configmap
            defaultMode: 0777
      containers:
        - name: df-setup-pod
          image: quay.io/ibmgaragecloud/cli-tools
          volumeMounts:
            - mountPath: /df-scripts
              name: df-scripts
          env:
            - name: ENV_CPD_NAMESPACE
              value: {{ .Values.cpd_namespace }}
            - name: ENV_USERNAME
              value: "admin"
            - name: ENV_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: admin-user-details
                  key: initial_admin_password
            - name: ENV_AWS_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-details
                  key: aws_access_key
            - name: ENV_AWS_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-details
                  key: aws_secret_key
            - name: ENV_S3_BUCKET_ID
              valueFrom:
                secretKeyRef:
                  name: aws-details
                  key: aws_s3_bucket_id
            - name: ENV_S3_BUCKET_REGION
              valueFrom:
                secretKeyRef:
                  name: aws-details
                  key: aws_region
            - name: ENV_S3_BUCKET_URL
              valueFrom:
                secretKeyRef:
                  name: aws-details
                  key: aws_s3_bucket_url
          command:
            - /bin/sh
          args:
            - '-c'
            - /df-scripts/datafabric_setup.sh
